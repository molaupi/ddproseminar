\documentclass[a4paper,UKenglish]{lipics-v2018}


\usepackage{microtype}

\bibliographystyle{plainurl}

\title{A summary on Delta Debugging and its uses}

\author{Moritz C. Laupichler}{Department of Informatics, Karlsruhe Institute of Technology, Germany}{moritz.laupichler@student.kit.edu}{}{}

\authorrunning{M.\, C. Laupichler}

\Copyright{Moritz C. Laupichler}

\subjclass{\ccsdesc[500]{Software and its engineering~Software testing and debugging}}

\keywords{Delta Debugging}

%Editor-only macros:: begin (do not touch as author)%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\EventEditors{Moritz Laupichler}
\EventNoEds{1}
\EventLongTitle{Proseminar Werkzeuge und Methoden der Software-Analyse, WS18/19}
\EventShortTitle{PS WMSA WS18/19}
\EventAcronym{WMSA}
\EventYear{2018}
\EventDate{October 19, 2018 -- February 1, 2019}
\EventLocation{Karlsruhe, Germany}
\EventLogo{}
\SeriesVolume{1}
\ArticleNo{M6}
\nolinenumbers
\hideLIPIcs


%%%%%%%% Own Packages %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Special symbol font
\usepackage{pifont}
\Pifont{pzd}

% Pseudocode algorithms
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\algrenewcommand{\algorithmiccomment}[1]{\hfill\(//\) #1}

% Colors
\usepackage{xcolor}
\definecolor{td-green}{rgb}{0,.5, 0}

%%%%%%%%%%%% Custom Commands %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% DD algorithms abbreviation
\newcommand{\sdd}[0]{\textit{simpledd}}
\newcommand{\dd}[0]{\textit{dd}}
\newcommand{\ddp}{\textit{dd\textsuperscript{+}}}
\newcommand{\dddiff}{\textit{dd\textsuperscript{diff}}}

% Colored text shortcuts
\newcommand{\green}[1]{\textcolor{td-green}{#1}}
\newcommand{\red}[1]{\textcolor{red}{#1}}
\newcommand{\gray}[1]{\textcolor{lightgray}{#1}}

% Yesterday and Today
\newcommand{\yd}[0]{\green{Yesterday}}
\newcommand{\td}[0]{\red{Today}}

% The global change set C
\newcommand{\C}[0]{\ensuremath{\mathcal{C}}}

% Possible results of the test function
\newcommand{\cmark}{\text{\ding{51}}}
\newcommand{\xmark}{\text{\ding{55}}}
\newcommand{\qmark}{\textbf{?}}

% Failing and passing configuration
\newcommand{\cpass}{\ensuremath{c_{\cmark}}}
\newcommand{\cfail}{\ensuremath{c_{\xmark}}}

% Definition subject
\newcommand{\defsub}[1]{\textbf{(#1)} }

% Math mode shortcuts
\newcommand{\set}[1]{\left \{ #1 \right \}}
\newcommand{\nN}[0]{\mathbb{N}}

% fail.c reference shortcut
\newcommand{\reffail}[0]{\hyperref[fig:fail.c]{\ensuremath{fail.c}}}

% r_pass and r_fail shortcuts
\newcommand{\rpass}[0]{\ensuremath{r_{\cmark}}}
\newcommand{\rfail}[0]{\ensuremath{r_{\xmark}}}
\newcommand{\spass}[0]{\ensuremath{s_{\cmark}}}
\newcommand{\sfail}[0]{\ensuremath{s_{\xmark}}}

% Cause-Effect-Chain arrow
\newcommand{\cecarrow}{\to}

\begin{document}

\maketitle

\begin{abstract}
	Debugging is tedious work for any programmer. This thought sparked the concept of Delta Debugging which was first described by Andreas Zeller in the late 90's and early 2000's. A simplistic scenario (``\yd\ my program worked, \td\ it does not. Why?'') was abstracted into algorithmically tackling debugging. The goal is simple: If every change between \yd\ and \td\ is seen as a Delta, which Deltas are responsible for the failure \td?

	This paper summarizes Zeller's early work on Delta Debugging \cite{Zeller:1999:YMP:318774.318946} and further gives an overview about several use cases for Delta Debugging that have been found in the early 2000's. 
\end{abstract}
	
\section{What is Delta Debugging?}
\label{sec:what_is_dd}

This section outlines the scenario that acts as the base for all following definitions and gives an idea of the goal of Delta Debugging.

\subsection{Yesterday and today}
\label{ydandtd}

Imagine a software development process where the latest changes to the code cause known tests to fail even though an older version of the code passed these exact tests. As the base of the Delta Debugging principle we need to define a simple abstraction of this point in the development process: We know a state \yd\ that passes the tests and a state \td\ that fails the tests. Furthermore we know all changes that yield \td\ when applied to \yd.\\
The goal of Delta Debugging is to automate extraction of the exact changes to \yd\ that cause the failure in \td.  

\subsection{The simple idea}
\label{ddidea}

The basic idea of Delta Debugging is similar to a binary search. Recursively the number of candidates for changes that cause \td\ to fail is lowered. By disregarding the changes that do not cause failure eventually we end up with the smallest set of changes that when applied to \yd\ causes the tests to fail. 



\section{Formalizing concepts}
\label{sec:formalizing_concepts}

The ideas described above need to be abstracted and formalized in order to approach Delta Debugging algorithms.

\subsection{Configurations}

\definition \defsub{Configuration} A change set $c \subseteq \C$ is called \textbf{configuration} where $\C$ is the set of all changes between \yd\ and \td.

\definition \defsub{Baseline} The empty configuration $\emptyset$ is called a \textbf{baseline}.

\definition \defsub{Test} The function $test: 2^{\C} \to \set{\cmark, \xmark, \qmark}$ determines the test outcome for a configuration. It returns one of three possible results: 
\begin{itemize}
	\item The tests pass: $\cmark$
	\item The tests fail: $\xmark$
	\item No result can be determined: $\qmark$
\end{itemize} 

Let $c \subseteq \C$ be a configuration. $test(c)$ models a suite of regression tests being run on the result of applying all changes in $c$ to \yd. So by definition $test(\emptyset) = \cmark$ ("Yesterday passes") and $test(\C) = \xmark$ ("Today fails") hold.

\definition \defsub{Failure-inducing configuration} A configuration $c$ is called \textbf{failure-inducing} iff 
\[ \forall c' : c \subseteq c' \subseteq \C \Rightarrow test(c') \ne \cmark \] 
holds.

\definition \defsub{Minimal failure-inducing configuration} A failure-inducing configuration $c$ is \textbf{minimal} iff 
\[ \forall c' \subsetneq c: test(c') \ne \xmark \]
holds.\\


These terms abstract the software development situation described in \ref{ydandtd}. The goal of Delta Debugging can now be stated as finding a minimal failure-inducing configuration in $\C$.

\section{Incrementally approaching a plausible DD algorithm}
\label{sec:ddalgorithms}

There are two major difficulties when approaching a Delta Debugging algorithm: interference and inconsistency. A na\"ive Delta Debugging algorithm called \sdd\ will be refined into the \dd\ algorithm and the \ddp\ algorithm in this chapter in order to describe and solve both difficulties. Finally, isolation of a minimal-failure inducing difference, an alternative approach to DD, is portrayed through the \dddiff\ algorithm.

\subsection{A na\"ive algorithm: \sdd}

The na\"ive algorithm \hyperref[fig:sdd]{\sdd} as shown in Figure \ref{fig:sdd} recursively splits \C\ into smaller and smaller parts until one failure-inducing change is found. In each recursion step the current set of changes, $c$, is partitioned into two halves, $c_1$ and $c_2$, and both halves are tested. The half that fails the tests is regarded in the next recursion step. The algorithm knows two cases, "Found in $c_1$" and "Found in $c_2$".
\\
\begin{figure}[h!]
\fbox{\begin{minipage}{\textwidth}
$simpledd(\C) = dd_1(\C)$ where \\
	
\begin{algorithmic}[1]
		\Function{$dd_1$}{$c: 2^{\C}$}
			\If{$|c| = 1$} \Return $c$ \EndIf
			\State Partition $c$ arbitrarily into two parts $c_1$, $c_2$ such that $|c_1| \approx |c_2| \approx |c|/2$
			\State \Return $\left \{ \text{\begin{tabular}{l l r}
				$dd_1(c_1)$ & if $test(c_1) = \xmark$ & \Comment("Found in $c_1$") \\
				$dd_1(c_2)$ & otherwise & \Comment("Found in $c_2$")
			\end{tabular}}\right.$
		\EndFunction
\end{algorithmic}
\end{minipage}}
\caption{The na\"ive DD algorithm \sdd}
\label{fig:sdd}
\end{figure}
\\

\begin{samepage}
	
It becomes evident that this algorithm is not effective because it is only capable of finding single changes that cause failure on their own. But what if multiple changes pass the test individually but only their combination induces failure? \\

\definition \defsub{Interference} Two configurations $c_1$ and $c_2$ \textbf{interfere} iff $test(c_1) = \cmark$, $test(c_2) = \cmark$ but $test(c_1 \cup c_2) = \xmark$. \\
\end{samepage}


\subsection{Dealing with interference: \dd}

\sdd\ is unable to handle the case of both $c_1$ and $c_2$ passing i.e. interfering configurations. A new algorithm \dd\ is created which behaves like \sdd\ but incorporates the case "Interference" as shown in Figure \ref{fig:dd}. In this case the algorithm searches for the failure-inducing change in $c_1$ while keeping $c_2$ applied and vice versa. By combining the results of both searches the interfering changes can be extracted.
\\
\begin{figure}[h!]
\fbox{\begin{minipage}{\textwidth}
	
$dd(\C) = dd_2(\C, \emptyset)$ where \\

\begin{algorithmic}[1]
	\Function{$dd_2$}{$c,r:2^\C$} $: 2^{\C}$
	\State Partition $c$ arbitrarily into two parts $c_1$, $c_2$ such that $|c_1| \approx |c_2| \approx |c|/2$
	\State $d_1 = dd_2(c_1, c_2 \cup r)$ \Comment("Search in $c_1$ while leaving $c_2$ applied")
	\State $d_2 = dd_2(c_2, c_1 \cup r)$ \Comment("Search in $c_2$ while leaving $c_1$ applied")\medskip  
	\State \Return $\left \{ \text{\begin{tabular}{l l r}
			$c$ & if $|c|=1$ & \Comment("Found") \\
			$dd_2(c_1,r)$ & if $test(c_1 \cup r) = \xmark$ & \Comment("Found in $c_1$")\\
			$dd_2(c_2,r)$ & if $test(c_2 \cup r) = \xmark$ & \Comment("Found in $c_2$")\\
			$d_1 \cup d_2$ & otherwise & \Comment("Interference")
		\end{tabular}}
			\right.$
	\EndFunction
\end{algorithmic}
\end{minipage}}
\caption{The \dd\ algorithm capable of dealing with interference.}
\label{fig:dd}
\end{figure}
\\

In $dd_2$ the parameter $c$ describes the configuration in which the algorithm is currently searching and the parameter $r$ contains all changes that remain applied during the search in $c$. \\

In \dd\ changes are combined arbitrarily and then tested. It is possible that no test result on the resulting configurations can be determined. 

\definition \defsub{Inconsistent configuration} A configuration $c \subseteq \C$ is called \textbf{inconsistent} iff $test(c) = \qmark$. \\

In the real world of code and regression tests this scenario is most likely caused by a combination of changes resulting in syntactical or semantic errors. An inconsistent configuration may also occur when a change is dependent on another change, that is not included in the configuration, or when the program execution fails during testing. 

\dd\ does not deal with inconsistent configurations. It delivers wrong results if the configurations that are tested in the "Found" cases are inconsistent.


\subsection{Dealing with inconsistency: \ddp}

The key to solving inconsistency is partitioning $c$ into more than two subsets making the sets of changes smaller. We know that the baseline $\emptyset$ and applying all changes $\C$ are consistent. By applying less changes to \yd\ or removing less changes from \td\ (s. case "Preference" below) the chances of the result being consistent are increased. If the algorithm runs into only inconsistent configurations the number of subsets is increased, thus increasing the chances of at least one configuration being consistent after. This solution requires the new Delta Debugging algorithm to handle any number $n$ of subsets whereas \dd\ only handles two change sets, $c_1$ and $c_2$, at a time.

\definition \defsub{Complement of configuration} Let $c \subseteq \C$ be a configuration that is currently being searched for failure-inducing changes. Let $r \subseteq \C$ be the changes that remain applied during the search. For a subset $a \subseteq c$ the \textbf{complement} is $\bar{a} = c \setminus (a \cup r)$.\\

The new Delta Debugging algorithm \ddp\ on the subsets $c_1, \dots, c_n$ as shown in Figure \ref{fig:ddp} knows four main cases:\\
\begin{description}
	\item["Found in $c_i$"] If testing any $c_i$ fails it contains a failure-inducing subset. Continue search in $c_i$.
	\item["Interference"] If any $c_i$ and $\bar{c_i}$ both pass they form an interference. Continue as in \dd.
	\item["Preference"] If any $c_i$ is unresolved but $\bar{c_i}$ passes then $c_i$ contains a failure-inducing subset. $c_i$ is then preferred. Continue search in $c_i$ while leaving $\bar{c_i}$ applied to promote consistency.
	\item["Try Again"] If none of the above cases apply then continue the search with $2n$ subsets. The chances of consistent configurations are increased.
\end{description}

\begin{figure}[H]
\fbox{\begin{minipage}{\textwidth}
	
$dd^+(\C) = dd_3(\C, \emptyset,2)$ where \\

\begin{algorithmic}[1]
	\Function{$dd_3$}{$c,r:2^\C, n: \nN$} $: 2^{\C}$
	\State Partition $c$ arbitrarily into $n$ parts $c_1, \dots, c_n$ such that $\forall i: |c_i| \approx |c|/n$
	\State let $\bar{c_i} = c \setminus (c_i \cup r), t_i = test(c_i \cup r), \bar{t_i} = test(\bar{c_i} \cup r)$
	\State let $c' = c \cap \bigcap \set{\bar{c_i} \mid \bar{t_i} = \xmark}, r' = r \cup \bigcup \set{c_i \mid t_i = \cmark}, n' = min (|c'|, 2n)$
	\State let $d_i = dd_3(c_i, \bar{c_i} \cup r, 2), \bar{d_i} = dd_3(\bar{c_i},c_i \cup r, 2)$
	\State \Return $\left \{ \text{\begin{tabular}{l l r}
		$c$ & if |c|=1 & \Comment("Found")\\
		$dd_3(c_i, r, 2)$ & if $t_i = \xmark$ for some $i$ & \Comment("Found in $c_i$")\\
		$d_i \cup \bar{d_i}$ & if $t_i = \cmark \wedge \bar{t_i} = \cmark$ for some $i$ & \Comment("Interference")\\
		$d_i$ & if $t_i = \qmark \wedge \bar{t_i} = \cmark$ for some $i$ & \Comment("Preference")\\
		$dd_3(c',r',n')$ & if $n < |c|$ & \Comment("Try Again")\\
		$c'$ & otherwise & \Comment("Nothing Left")
	\end{tabular}}\right.$
	\EndFunction
\end{algorithmic}
\end{minipage}}
\caption{The \ddp\ algorithm capable of dealing with unresolved test cases.}
\label{fig:ddp}
\end{figure}

\lemma \ddp\ returns a minimal failure-inducing subset of changes as long as the subset is safe, i.e. they can be applied to \yd\ or removed from \td\ without causing an inconsistency. \ddp\ has linear time complexity.

\proof See \cite{Zeller:1999:YMP:318774.318946}.

\subsection{Isolating a minimal difference: \dddiff}

All the above Delta Debugging algorithms have focused on simplification of a failing configuration. The idea of simplification is to eliminate as many non-failure-inducing changes from $\C$ as possible to find out what the actual changes between \yd\ and \td\ were that cause the failure today.

Another goal that can be achieved by Delta Debugging is the isolation of the minimal failure-inducing difference between \yd\ and \td. Isolation means to replicate this difference through two other configurations \cpass\ and \cfail\ that will not make any sense from a production standpoint but portray the difference in a minimal and thus simple to understand fashion. This is exactly what the programmer wants when debugging the code: A simplistic reconstruction of what separates passing code from the known failing code in the given context, i.e. the reason why \td\ fails.\\

In more technical terms the goal is to find two configurations \cpass\ and \cfail, such that $\emptyset \subseteq \cpass \subsetneq \cfail \subseteq \C$, $test(\cpass) = \cmark$ and $test(\cfail) = \xmark$ hold and the difference between the configurations $\Delta = \cfail \setminus \cpass$ is minimal.

\definition \label{def:minimal_difference} \defsub{Minimal failure-inducing difference} Let \cpass\ and \cfail\ be two test cases with $\emptyset \subseteq \cpass \subsetneq \cfail \subseteq \C$. Their difference $\Delta = \cfail \setminus \cpass$ is \textbf{minimal} iff \[ \forall \Delta' \subsetneq \Delta : test(\cpass \cup \Delta') \ne \cmark \text{ and } test(\cfail \setminus \Delta') \ne \xmark \]

The number of subsets of $\Delta$ is exponential so we relax the definition of minimality to n-minimality.

\definition \label{def:n-minimal_difference} \defsub{N-minimal failure-inducing difference} Let \cpass\ and \cfail\ be defined as above. Their difference $\Delta = \cfail \setminus \cpass$ is \textbf{n-minimal} iff \[ \forall \Delta' \subsetneq \Delta : |\Delta'| \le n \Rightarrow (test(\cpass \cup \Delta') \ne \cmark \text{ and } test(\cfail \setminus \Delta') \ne \xmark) \] 

We aim at finding two configurations with a \textit{1-minimal failure-inducing difference} - that is a configuration \cfail\ where taking away any change $\delta \in \Delta$ will make the failure disappear.\\

The idea of the isolation algorithm \dddiff\ is to increase the size of \cpass\ or decrease the size of \cfail\ until their difference is 1-minimal. The algorithm is initialized with $\cpass = \emptyset$ and $\cfail = \C$. The difference $\Delta = \cfail \setminus \cpass$ is partitioned into $n$ disjoint subsets $\Delta_1, ..., \Delta_n$ much as in \ddp. Then the following cases are evaluated:

\begin{description}
  	\item[``reduce to subset''] If adding any $\Delta_i$ to the current \cpass\ yields a failing configuration, this configuration can be used as a new \cfail\ as it is smaller than the current \cfail. Recurse with a partition granularity of 2.
  	\item[``increase to complement''] If removing any $\Delta_i$ from the current \cfail\ yields a passing configuration, this configuration can be used as a new \cpass\ as it is larger than the current \cpass. Recurse with a partition granularity of 2.
  	\item[``increase to subset''] If adding any $\Delta_i$ to the current \cpass\ yields a passing configuration, this configuration can be used as a new \cpass\ as it is larger than the current \cpass. Recurse with a partition granularity of $n-1$, as the difference changes only by $\Delta_i$ and thus all coarser partitions would result in unresolved tests again.
  	\item[``reduce to complement''] If removing any $\Delta_i$ from the current \cfail\ yields a failing configuration, this configuration can be used as a new \cfail\, as it is smaller than the current \cfail. Recurse with a partition granularity of $n-1$ (s.a.).
  	\item[``increase granularity''] If none of the above cases apply, i.e. the tests all remain unresolved, then the granularity of the partition of $\Delta$ is increased as in \ddp. 
  	\item[``done''] If $n \ge |\Delta|$ the granularity can not be increased further. In that case every $\Delta_i$ only contains one change. If \cpass\ cannot be increased and \cfail\ not be reduced at that point, the difference between them is 1-minimal and they are returned.\\
\end{description}
The full \dddiff\ algorithm is shown in Figure \ref{fig:dddiff}. It is described by Zeller as the successor to \hyperref[fig:ddp]{\ddp} and is recommended to generally replace \ddp\ as it is superior in performance and result quality \cite{Zeller:2002:SIF:506201.506206}. \\

\begin{figure}[H]
	\fbox{
		\begin{minipage}{\textwidth}

		$\dddiff(\C)=dd_4(\emptyset, \C, 2)$ where \\

				\begin{algorithmic}[1]
					\Function{$dd_4$}{$\cpass,\cfail:2^{\C}$, $n: \nN$}: $2^{\C} \times 2^{\C}$
					\State let $\Delta = \cfail \setminus \cpass$
					\State Partition $\Delta$ arbitrarily into $n$ parts $\Delta_1, \dots, \Delta_n$ such that $\forall i: |\Delta_i| \approx |\Delta|/n$
					\State let $t_{\cmark, i} = test(\cpass \cup \Delta_i)$ for $i \in \set{1, \dots, n}$ \Comment(``test for larger passing configuration'')
					\State let $t_{\xmark, i} = test(\cfail \setminus \Delta_i)$ for $i \in \set{1, \dots, n}$ \Comment(``test for smaller failing configuration'')
					\State \Return $\left \{ \text{\begin{tabular}{l l r}
						$dd_4(\cpass, \cpass \cup \Delta_i,2)$ & if $t_{\cmark, i} = \xmark$ & \Comment(``reduce to subset'') \\
						$dd_4(\cfail \setminus \Delta_i, \cfail, 2)$ & if $t_{\xmark, i} = \cmark$ & \Comment(``increase to complement'')\\
						$dd_4(\cpass \cup \Delta_i, \cfail, max(n-1, 2))$ & if $t_{\cmark, i} = \cmark$ & \Comment(``increase to subset'')\\
						$dd_4(\cpass, \cfail \setminus \Delta_i, max(n-1,2))$ & if $t_{\xmark, i} = \xmark$ & \Comment(``reduce to complement'')\\
						$dd_4(\cpass, \cfail, min(2n, |\Delta|))$ & if $n < |\Delta|$ & \Comment(``increase granularity'')\\
						(\cpass, \cfail) & otherwise & \Comment(``done'')
					\end{tabular}}\right.$
					(check the first cases for all $i \in \set{1, \dots, n}$)
					\EndFunction
				\end{algorithmic}
		\end{minipage}
	}
	\caption{The Delta Debugging algorithm for finding two configurations with minimal difference, \dddiff. It finds $(\cfail, \cpass) = \dddiff(\C)$ such that $\emptyset \subseteq \cpass \subsetneq \cfail \subseteq \C$, $test(\cpass) = \cmark$, $test(\cfail) = \xmark$, and $\Delta = \cfail \setminus \cpass$ is 1-minimal.}
	\label{fig:dddiff}
\end{figure}

Isolation has two technical advantages over simplification:
\begin{enumerate}
	\item It takes less tests to find a 1-minimal failure-inducing difference than to find a minimal failure-inducing subset of changes \cite{Zeller:2002:SIF:506201.506206}.
	This is because isolation can improve the current configurations if either a test fails or a test passes whereas simplification needs a test to fail to reduce the size of the current subset of changes. Simply put, isolation approaches the solution from both sides simultaneously while simplification only works in one way.
	\item The simplification algorithm \ddp\ relies on monotone configurations, i.e. $test(c)=\cmark \Rightarrow (\forall c' \subseteq c : test(c') = \cmark)$ holds for all $c \in \C$. The isolation algorithm \dddiff\ does not need to assume all configurations are monotone. With some adaptations it can still make use of that property if it is given, though \cite{Zeller:2002:SIF:506201.506206}.
\end{enumerate}

\section{Exemplary use cases}
\label{sec:use_cases}

In this chapter three exemplary use cases for Delta Debugging will be shown.

\subsection{Program input analysis}

If a certain input is known to cause a program to fail execution then Delta Debugging can be used to analyse which part of the program input is responsible for the failure. The \ddp\ algorithm as defined above can be used without any modifications. It is necessary, though, to define certain abstract concepts in the context of input analysis.\\
\begin{itemize}
  	\item We assume a known minimal input for the program at hand that does not cause failure. In many cases this minimal input would be some sort of "empty" input, be it no data, zero values, etc. This minimal input is regarded as the \yd\ state.
  	\item The known failing input is regarded as the \td\ state.
  	\item A change is defined as the smallest possible difference between any two possible inputs, usually a letter, number or other token of data. $\C$ can then be any set of changes that convert the minimal input \yd\ to the failing input \td.
  	\item The $test$ function returns $\xmark$ if exactly the known error occurs on program execution. It returns $\cmark$ if no error occurs and $\qmark$ in all other cases. 
\end{itemize}

Running \ddp\ with these concrete definitions finds the parts of the input that are responsible for the failure. If the input itself is faulty the error will be revealed directly. If the error lies within the program the algorithm delivers a starting point for manually debugging the error.

Consider as an example the C program \reffail\ which caused the GNU C Compiler (GCC) in version 2.95.2 (on Intel-Linux with optimization enabled) to crash. The program looks like correct C code that should be compiled properly. We'd like to use Delta Debugging to find out which part of \reffail\ is responsible for the crash. An empty C program is regarded as the \yd\ state and \reffail\ as the \td\ state. A change is defined as a C language token. $\C$ is comprised of all tokens in \reffail. As depicted in Figure \ref{fig:ddponfail} \ddp\ only takes 21 tests to find out that the C tokens "$+ 1.0$" are a minimal failure-inducing set of changes.
\\
\begin{figure}[h!]
	\fbox{
		\begin{minipage}{\textwidth}
		\begin{centering}\texttt{
					\begin{algorithmic}[1]
							\State double \textbf{mult}(double z[], int n)
							\State $\{$
							\State \quad int i,j;
							\State \quad i = 0;
							\State \quad for(j = 0; j < n; j++) $\{$
							\State \quad \quad i = i + j + 1;
							\State \quad \quad z[i] = z[i] * (z[0] + 1.0);
							\State \quad $\}$
							\State \quad return z[n];
							\State $\}$
					\end{algorithmic}}
		\end{centering}
		\end{minipage}
	}
	\caption{The $fail.c$ program that crashes GCC}
	\label{fig:fail.c}
\end{figure}
\\
\begin{figure}[h!]
	\fbox{
		\begin{minipage}{\textwidth}
			\begin{centering}
			\begin{tabular}{clc}
				\# & GCC input & test \\
				\hline
				1 & double mult($\dots$) $\{ int \; i, j; \; i = 0; \; for (\dots) \{ \dots\} \dots\}$ & $\xmark$ \\
				2 &\gray{ double mult($\dots$) $\{ int \; i, j; \; i = 0; \; for (\dots) \{ \dots\} \dots\}$} & $\cmark$ \\
				3 & double mult($\dots$) $\{\gray{ int \; i, j; \; i = 0; \; for (\dots) \{ \dots\} \dots}\}$ & $\cmark$ \\
				4 & double mult($\dots$) $\{ int \; i, j; \; i = 0; \; \gray{for (\dots) \{ \dots\} \dots}\}$ & $\cmark$ \\
				5 & double mult($\dots$) $\{ int \; i, j; \; i = 0; \; for (\dots) \{ \dots\}\gray{ \dots}\}$ & $\xmark$ \\
				6 & double mult($\dots$) $\{ int \; i, j; \; i = 0; \; for (\gray{\dots}) \{ \dots\} \gray{\dots}\}$ & $\cmark$ \\

				\vdots & \multicolumn{1}{c}{\vdots} & \vdots \\
				18 & \multicolumn{1}{c}{\dots \quad $z[i] = z[i] * (z[0] + 1.0);$ \quad \dots } & \xmark \\
				19 & \multicolumn{1}{c}{\dots \quad $z[i] = z[i] * (z[0] \gray{+ 1.0});$ \quad \dots } & \cmark \\
				20 & \multicolumn{1}{c}{\dots \quad $z[i] = z[i] * (z[0] \gray{+} 1.0);$ \quad \dots } & \qmark \\
				21 & \multicolumn{1}{c}{\dots \quad $z[i] = z[i] * (z[0] + \gray{1.0});$ \quad \dots } & \qmark \\
			\end{tabular}
			\end{centering}
		\end{minipage}
	}
	\caption{How \ddp\ finds the part of \texttt{fail.c} that is responsible for GCC crashing.}
	\label{fig:ddponfail}
\end{figure}


\subsection{Program runtime analysis}

It can be of great help for the software developer to automatically determine the specific parts of the program input that cause the failure. The information gathered from the above method can be used by the developer to manually trace the responsible input data to the crash. Considering how a minuscule input change can cause entirely different execution paths this task is tedious if not impossible.
Delta Debugging can help trace the error from the root to the failure during program execution as well, though. Given a debugging framework that is able to access \hyperref[def:program_state]{program states} during execution, DD is used on the program states of two \hyperref[def:program_run]{program runs} \rpass\ and \rfail\ at significant locations to deduce a \textit{Cause-Effect-Chain (CEC)}.

The entire program execution is determined by a set of circumstances. We focus on changeable circumstances, more specifically the circumstances that influence the test outcome. A program run, i.e. one specific sequence of program states, is determined only by the set of circumstances that induce the specific run.

\definition \label{def:program_run} \defsub{Circumstances and program runs} Let $R$ be the set of all possible circumstance configurations. A (program) run is defined as a configuration of circumstances, so every $r \in R$ is called a run.\\

For our intents and purposes it is sufficient to only consider the program input as the changeable circumstances as we assume the error lies within the program code and occurs independently of operating systems, hardware and other environmental factors. Thus, in our case a program run is equivalent to just the specific input that induces the program run.

\definition \label{def:program_state} \defsub{Program states} A program state $p$ is a set of \textit{(variable, value)} pairs that unambiguously determine further program execution. The program state always corresponds to a specific point in a \hyperref[def:program_run]{program run}.\\

In order to use Delta Debugging on program states we need to once again define concrete realizations of the abstract DD concepts:

\begin{itemize}
	\item We assume a program run \rfail\ based on some known faulty input that crashes the program with a certain error. We further assume knowledge of a passing program run \rpass\ that runs and terminates correctly.
	\item We use Delta Debugging repeatedly to compare program states of \rfail\ and \rpass\ at multiple significant locations \footnote{The number of comparisons vary depending on program size. It defines the granularity of the resulting Cause-Effect-Chain. The location of a comparison should give an overview of the state of the execution and should be reached by most program runs. The locations define the informative power of the Cause-Effect-Chain.}. Each time Delta Debugging is used the program state \sfail\ of \rfail\ is regarded as \td\ and the state \spass\ of \rpass\ is regarded as \yd.
	\item A change between two program states is defined as either a different value of a variable or a variable that only exists in one program state.
	\item The set $\C$ contains all such changes between \spass\ and \sfail\ for each comparison, i.e. each individual execution of Delta Debugging.
	\item The \textit{test} function models further program execution from a given program state. It returns \xmark\ if the program crashes with the exact known error and \cmark\ if the program terminates correctly. In all other cases \qmark\ is returned (e.g. a crash with a different error). 
\end{itemize}

The definition of the test function makes evident why a debugging framework is needed. We need to be able to extract the program state \spass\ of \rpass\ and \sfail\ of \rfail\ at a certain point in order to compare them. More importantly, though, the program code needs to be executed from that point repeatedly with different program states. The states might even be artificial, i.e. they are created by applying arbitrary subsets of $\C$ to \spass\ and would never occur in any run without outside interference. In that case unexpected behaviour is inevitable and memory leaks are likely. The framework needs to make sure no harm is done to the machine or other software.

Given the above concrete definitions the \hyperref[fig:ddp]{\ddp} algorithm can be used repeatedly to compare \rpass\ and \rfail. The result of each execution of \ddp\ will be a set of \textit{(variable, value)} pairs in \sfail\ that are responsible for the failure down the line. A Cause-Effect-Chain from the input to the failure is then created by chaining together the results of each state comparison. The CEC can give a detailed look into the root cause of the error.\\

Consider as an example the above example program \reffail\ that crashes GCC. Applying GCC on $fail.c$ is regarded as \rfail\ and applying GCC to an empty C program as \rpass\ (compiling no code obviously terminates correctly). Andreas Zeller's experimental \textit{HOWCOME} algorithm\footnote{The \textit{HOWCOME} algorithm uses Delta Debugging as described above and incorporates technical issues like the extraction of program states and applying the debugging framework \cite{Zeller:2002:ICC:587051.587053}.}
compares the runs at the function \textit{main} shortly after the start of the program, at the function $combine\_instructions$ and at each hit of the function $if\_then\_else\_cond$. \textit{HOWCOME} yields a \hyperref[fig:failcec]{Cause-Effect-Chain} that includes the comparisons at those locations as shown in Figure \ref{fig:failcec}.

\begin{figure}[h!]
	\fbox{
		\begin{minipage}{\textwidth}
			\begin{enumerate}
			\item Execution reaches \textbf{main}. \\Since the program was invoked as ``ccl -O fail.i'' variable \textbf{$argv[2]$} is now \textbf{``fail.i''}
			\item Execution reaches \textbf{combine\_instructions}. \\ Since $argv[2]$ was ``fail.i'', variable \textbf{$*first\_loop\_store\_insn\cecarrow fld[1].rtx \cecarrow fld[1].rtx \cecarrow fld[3].rtx \cecarrow fld[1].rtx$} is now \textbf{$\langle new rtx\_def\rangle$}.
			\item Execution reaches \textbf{if\_then\_else\_cond (95th hit)}. \\ Since $*first\_loop\_store\_insn\cecarrow fld[1].rtx \cecarrow fld[1].rtx \cecarrow fld[3].rtx \cecarrow fld[1].rtx$ was $\langle new rtx\_def\rangle$, variable \textbf{$link \cecarrow fld[0].rtx \cecarrow fld[0].rtx$} is now \textbf{$link$}.
			\item Execution ends. \\ Since variable $link \cecarrow fld[0].rtx \cecarrow fld[0].rtx$ was $link$, the program now \textbf{terminates with a SIGSEGV signal}. The program fails.
			\end{enumerate}
		\end{minipage}
	}
	\caption{The Cause-Effect-Chain that is deduced by \textit{HOWCOME} for \reffail\ \cite{Zeller:2002:ICC:587051.587053}. Only the last hit of $if\_then\_else\_cond$ is shown.}
	\label{fig:failcec}
\end{figure}

The CEC contains the cause for the failure but the fault in the program has to be extracted by the programmer as it is a question of intended vs faulty states. The programmer uses the CEC to find the transition between the last intended and the first faulty program state. In between these two states a more detailed analysis can be conducted using a finer granularity of compared program states which eventually leads to the error in the program itself. The distinction between intended and faulty states may also be conducted by heuristics which would allow the system to automatically search with a finer granularity in the desired section of the runs.



\subsection{Minimizing random unit test cases}

An important part of software testing today is randomized tests. Given a unit under test (UUT) a randomized test case generator will create random sequences of instructions to the UUT with randomized input data. The test driver will use the generated sequences to test the functionality of the UUT even under implausible circumstances. Non-randomized test drivers with test cases written by the programmer will not be able to cover all these cases \cite{Lei:2005:MRU:1104997.1105255}.

The problem with randomized unit testing is that the randomly generated failing test cases are often not useful for the programmer. When debugging the code, the failing test cases hold little value as they tend to contain lots of unnecessary instructions, which hides the reason for the failure. 

After generating random test cases it would be useful to minimize the failing test cases so they only contain the instructions that are relevant for inducing the failure. This is where Delta Debugging comes to play (\cite{Lei:2005:MRU:1104997.1105255}): By viewing an empty test case as the \yd\ state and the randomly generated failing test case as the \td\ state, we can apply a Delta Debugging algorithm to minimize the test case. We define the abstract DD concepts in this context more concretely:

\begin{itemize}
	\item Every instruction in the randomly generated failing test case is regarded as one change.
	\item $\C$ is regarded as all instructions in the test case in order.
	\item The \textit{test} function models the execution of the instructions in the test driver. The instructions are always executed in the same order as they were in the original randomly generated failing test case. 
\end{itemize}

Both \hyperref[fig:ddp]{\ddp} and \hyperref[fig:dddiff]{\dddiff} can be used in this scenario. \ddp\ will return a minimal sequence of instructions that induces the same error as the original test case whereas \dddiff\ returns two test cases, one passing and one failing, with a minimal difference. \dddiff\ will likely be more efficient (\cite{Zeller:2002:SIF:506201.506206})
 but it remains a matter of context which result is more useful for the debugging of the program code.\\

Static slicing can be initially applied to the test cases to improve the runtime of the test case minimization. In static slicing Read-Write-Data-Dependencies between the instructions are analyzed and only the instructions that could influence the last instruction remain in the test. This method is a static analysis of the test cases, meaning it does not actually need to execute the tests in order to find instructions that are irrelevant for the failure. This gives static slicing a runtime advantage compared to minimization by Delta Debugging. At the same time static slicing is not as effective as DD minimization. A combination of both, i.e. first applying static slicing and then DD minimization, will retain the advantages of both methods, though: It has a lower runtime but is just as efficient as DD minimization \cite{Leitner:2007:EUT:1321631.1321698}.

\section{Contribution}
\label{sec:contribution}

This paper is not a research paper. It only summarizes work of others from the given citations and does not incorporate any research conducted by the author. The content of sections \ref{sec:what_is_dd}, \ref{sec:formalizing_concepts} and \ref{sec:ddalgorithms} is mostly taken from \cite{Zeller:1999:YMP:318774.318946}. \dddiff\ is taken from \cite{Zeller:2002:SIF:506201.506206} where it is called \textit{dd}. The use cases in section \ref{sec:use_cases} and most importantly the $fail.c$ case studies have been taken from \cite{Zeller:2002:ICC:587051.587053} and \cite{Lei:2005:MRU:1104997.1105255}. Static slicing in section \ref{sec:use_cases} is a concept portrayed in \cite{Leitner:2007:EUT:1321631.1321698}.

\section{Conclusion}
\label{sec:conclusion}
Zeller initially defined Delta Debugging as abstract as possible \cite{Zeller:1999:YMP:318774.318946}. This allows the method to be applied to a variety of use cases in testing and debugging as outlined in section \ref{sec:use_cases}. The abstractness is also a weakness, though, as in praxis every time Delta Debugging is applied a variety of these abstract concepts need to be concretized. Bringing the Delta Debugging algorithms that are portrayed in section \ref{sec:ddalgorithms} into a practical context might still be a lot of work to the human debugger.

Nonetheless Delta Debugging has its rightful place in the scientific approach to debugging as the idea continues to find new uses today, almost 20 years after its introduction by Zeller (The \href{https://dl.acm.org/dl.cfm}{ACM Digital Library} mentions 6 papers directly incorporating Delta Debugging in 2017/2018). An important development of Delta Debugging is Hierarchical Delta Debugging \cite{Misherghi:2006:HHD:1134285.1134307} which speeds up the process by making use of hierarchical structures in data, e.g. when debugging XML code.

\bibliography{article}

\end{document}